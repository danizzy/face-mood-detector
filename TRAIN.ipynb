{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22ee281d-8de5-4c79-ba14-8b1a28ed0727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e5d22e6-ba4c-4411-8620-cadf37586838",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train'\n",
    "val_dir = 'data/test'\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1495d142-4e5f-45f1-a8b0-7708e08ec179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28710 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6de6bc8b-f18d-4338-8dc6-379e87b8b9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cddd85dd-7704-4b42-bfd7-11c9489f5d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a38509b-98c4-488e-a334-5d402c93434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fc3c859-e45c-4fcb-b0b8-a867a05789aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b566002b-16bd-4f31-bc36-05e5b079c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9862a299-5fe1-4037-a165-db1e0e275347",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.ocl.setUseOpenCL(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec2757fc-e746-4510-8585-24327a6441d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "995f38cc-3ec1-404a-9de5-440c2fb0c85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "448/448 [==============================] - 216s 477ms/step - loss: 1.8033 - accuracy: 0.2569 - val_loss: 1.7467 - val_accuracy: 0.3334\n",
      "Epoch 2/50\n",
      "448/448 [==============================] - 210s 468ms/step - loss: 1.6329 - accuracy: 0.3639 - val_loss: 1.5529 - val_accuracy: 0.4072\n",
      "Epoch 3/50\n",
      "448/448 [==============================] - 210s 468ms/step - loss: 1.5380 - accuracy: 0.4111 - val_loss: 1.4778 - val_accuracy: 0.4309\n",
      "Epoch 4/50\n",
      "448/448 [==============================] - 224s 501ms/step - loss: 1.4709 - accuracy: 0.4379 - val_loss: 1.4152 - val_accuracy: 0.4598\n",
      "Epoch 5/50\n",
      "448/448 [==============================] - 222s 496ms/step - loss: 1.4120 - accuracy: 0.4586 - val_loss: 1.3650 - val_accuracy: 0.4831\n",
      "Epoch 6/50\n",
      "448/448 [==============================] - 221s 493ms/step - loss: 1.3594 - accuracy: 0.4866 - val_loss: 1.3258 - val_accuracy: 0.4947\n",
      "Epoch 7/50\n",
      "448/448 [==============================] - 225s 501ms/step - loss: 1.3169 - accuracy: 0.5040 - val_loss: 1.2861 - val_accuracy: 0.5120\n",
      "Epoch 8/50\n",
      "448/448 [==============================] - 213s 475ms/step - loss: 1.2779 - accuracy: 0.5154 - val_loss: 1.2590 - val_accuracy: 0.5198\n",
      "Epoch 9/50\n",
      "448/448 [==============================] - 153s 341ms/step - loss: 1.2411 - accuracy: 0.5312 - val_loss: 1.2330 - val_accuracy: 0.5293\n",
      "Epoch 10/50\n",
      "448/448 [==============================] - 131s 293ms/step - loss: 1.2073 - accuracy: 0.5468 - val_loss: 1.2132 - val_accuracy: 0.5399\n",
      "Epoch 11/50\n",
      "448/448 [==============================] - 133s 297ms/step - loss: 1.1778 - accuracy: 0.5590 - val_loss: 1.1928 - val_accuracy: 0.5438\n",
      "Epoch 12/50\n",
      "448/448 [==============================] - 134s 298ms/step - loss: 1.1533 - accuracy: 0.5667 - val_loss: 1.1749 - val_accuracy: 0.5558\n",
      "Epoch 13/50\n",
      "448/448 [==============================] - 134s 300ms/step - loss: 1.1202 - accuracy: 0.5812 - val_loss: 1.1535 - val_accuracy: 0.5650\n",
      "Epoch 14/50\n",
      "448/448 [==============================] - 132s 296ms/step - loss: 1.0996 - accuracy: 0.5890 - val_loss: 1.1450 - val_accuracy: 0.5657\n",
      "Epoch 15/50\n",
      "448/448 [==============================] - 133s 297ms/step - loss: 1.0710 - accuracy: 0.6001 - val_loss: 1.1502 - val_accuracy: 0.5663\n",
      "Epoch 16/50\n",
      "448/448 [==============================] - 134s 299ms/step - loss: 1.0463 - accuracy: 0.6104 - val_loss: 1.1184 - val_accuracy: 0.5822\n",
      "Epoch 17/50\n",
      "448/448 [==============================] - 132s 294ms/step - loss: 1.0267 - accuracy: 0.6171 - val_loss: 1.1092 - val_accuracy: 0.5872\n",
      "Epoch 18/50\n",
      "448/448 [==============================] - 133s 296ms/step - loss: 0.9978 - accuracy: 0.6287 - val_loss: 1.1076 - val_accuracy: 0.5864\n",
      "Epoch 19/50\n",
      "448/448 [==============================] - 132s 295ms/step - loss: 0.9802 - accuracy: 0.6352 - val_loss: 1.0921 - val_accuracy: 0.5950\n",
      "Epoch 20/50\n",
      "448/448 [==============================] - 133s 297ms/step - loss: 0.9556 - accuracy: 0.6480 - val_loss: 1.0917 - val_accuracy: 0.5936\n",
      "Epoch 21/50\n",
      "448/448 [==============================] - 136s 303ms/step - loss: 0.9332 - accuracy: 0.6555 - val_loss: 1.0827 - val_accuracy: 0.6006\n",
      "Epoch 22/50\n",
      "448/448 [==============================] - 133s 297ms/step - loss: 0.9087 - accuracy: 0.6661 - val_loss: 1.0868 - val_accuracy: 0.5986\n",
      "Epoch 23/50\n",
      "448/448 [==============================] - 134s 300ms/step - loss: 0.8892 - accuracy: 0.6739 - val_loss: 1.0859 - val_accuracy: 0.5989\n",
      "Epoch 24/50\n",
      "448/448 [==============================] - 133s 297ms/step - loss: 0.8611 - accuracy: 0.6816 - val_loss: 1.0815 - val_accuracy: 0.6056\n",
      "Epoch 25/50\n",
      "448/448 [==============================] - 133s 297ms/step - loss: 0.8388 - accuracy: 0.6920 - val_loss: 1.0755 - val_accuracy: 0.6027\n",
      "Epoch 26/50\n",
      "448/448 [==============================] - 1265s 3s/step - loss: 0.8197 - accuracy: 0.6986 - val_loss: 1.0696 - val_accuracy: 0.6169\n",
      "Epoch 27/50\n",
      "448/448 [==============================] - 215s 480ms/step - loss: 0.7971 - accuracy: 0.7083 - val_loss: 1.0732 - val_accuracy: 0.6117\n",
      "Epoch 28/50\n",
      "448/448 [==============================] - 216s 482ms/step - loss: 0.7724 - accuracy: 0.7191 - val_loss: 1.0884 - val_accuracy: 0.6091\n",
      "Epoch 29/50\n",
      "448/448 [==============================] - 214s 478ms/step - loss: 0.7488 - accuracy: 0.7255 - val_loss: 1.0815 - val_accuracy: 0.6140\n",
      "Epoch 30/50\n",
      "448/448 [==============================] - 1625s 4s/step - loss: 0.7302 - accuracy: 0.7321 - val_loss: 1.0658 - val_accuracy: 0.6214\n",
      "Epoch 31/50\n",
      "448/448 [==============================] - 201s 449ms/step - loss: 0.7089 - accuracy: 0.7420 - val_loss: 1.0759 - val_accuracy: 0.6233\n",
      "Epoch 32/50\n",
      "448/448 [==============================] - 209s 467ms/step - loss: 0.6849 - accuracy: 0.7526 - val_loss: 1.0822 - val_accuracy: 0.6164\n",
      "Epoch 33/50\n",
      "448/448 [==============================] - 210s 468ms/step - loss: 0.6596 - accuracy: 0.7573 - val_loss: 1.0761 - val_accuracy: 0.6200\n",
      "Epoch 34/50\n",
      "448/448 [==============================] - 209s 465ms/step - loss: 0.6397 - accuracy: 0.7684 - val_loss: 1.1082 - val_accuracy: 0.6138\n",
      "Epoch 35/50\n",
      "448/448 [==============================] - 208s 464ms/step - loss: 0.6254 - accuracy: 0.7738 - val_loss: 1.0898 - val_accuracy: 0.6186\n",
      "Epoch 36/50\n",
      "448/448 [==============================] - 210s 469ms/step - loss: 0.5954 - accuracy: 0.7860 - val_loss: 1.0942 - val_accuracy: 0.6225\n",
      "Epoch 37/50\n",
      "448/448 [==============================] - 210s 468ms/step - loss: 0.5778 - accuracy: 0.7920 - val_loss: 1.1034 - val_accuracy: 0.6253\n",
      "Epoch 38/50\n",
      "448/448 [==============================] - 210s 469ms/step - loss: 0.5596 - accuracy: 0.7976 - val_loss: 1.1216 - val_accuracy: 0.6228\n",
      "Epoch 39/50\n",
      "448/448 [==============================] - 207s 461ms/step - loss: 0.5390 - accuracy: 0.8043 - val_loss: 1.1125 - val_accuracy: 0.6214\n",
      "Epoch 40/50\n",
      "448/448 [==============================] - 209s 466ms/step - loss: 0.5271 - accuracy: 0.8102 - val_loss: 1.1170 - val_accuracy: 0.6242\n",
      "Epoch 41/50\n",
      "448/448 [==============================] - 213s 475ms/step - loss: 0.5069 - accuracy: 0.8171 - val_loss: 1.1289 - val_accuracy: 0.6222\n",
      "Epoch 42/50\n",
      "448/448 [==============================] - 209s 466ms/step - loss: 0.4945 - accuracy: 0.8241 - val_loss: 1.1362 - val_accuracy: 0.6275\n",
      "Epoch 43/50\n",
      "448/448 [==============================] - 207s 461ms/step - loss: 0.4730 - accuracy: 0.8272 - val_loss: 1.1380 - val_accuracy: 0.6271\n",
      "Epoch 44/50\n",
      "448/448 [==============================] - 206s 460ms/step - loss: 0.4599 - accuracy: 0.8346 - val_loss: 1.1458 - val_accuracy: 0.6249\n",
      "Epoch 45/50\n",
      "448/448 [==============================] - 206s 460ms/step - loss: 0.4393 - accuracy: 0.8420 - val_loss: 1.1682 - val_accuracy: 0.6218\n",
      "Epoch 46/50\n",
      "448/448 [==============================] - 208s 464ms/step - loss: 0.4297 - accuracy: 0.8473 - val_loss: 1.1707 - val_accuracy: 0.6260\n",
      "Epoch 47/50\n",
      "448/448 [==============================] - 211s 471ms/step - loss: 0.4088 - accuracy: 0.8515 - val_loss: 1.1915 - val_accuracy: 0.6277\n",
      "Epoch 48/50\n",
      "448/448 [==============================] - 209s 467ms/step - loss: 0.4009 - accuracy: 0.8549 - val_loss: 1.1886 - val_accuracy: 0.6271\n",
      "Epoch 49/50\n",
      "448/448 [==============================] - 209s 466ms/step - loss: 0.3839 - accuracy: 0.8620 - val_loss: 1.2369 - val_accuracy: 0.6275\n",
      "Epoch 50/50\n",
      "448/448 [==============================] - 216s 482ms/step - loss: 0.3697 - accuracy: 0.8671 - val_loss: 1.2312 - val_accuracy: 0.6247\n"
     ]
    }
   ],
   "source": [
    "emotion_model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\n",
    "emotion_model_info = emotion_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=28709 // 64,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=7178 // 64)\n",
    "emotion_model.save_weights('emotion_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb7d5d36-0814-40fa-932f-37e27658b8b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1525 predict_step\n        return self(x, training=False)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:394 call\n        outputs = layer(inputs, **kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:1447 call\n        return getattr(self._module, self._method_name)(*args, **kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py:1006 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\layers\\convolutional.py:245 call\n        outputs = self._convolution_op(inputs, self.kernel)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1012 convolution_v2\n        return convolution_internal(\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1142 convolution_internal\n        return op(\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:2596 _conv2d_expanded_batch\n        return gen_nn_ops.conv2d(\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:968 conv2d\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:628 _apply_op_helper\n        _SatisfiesTypeConstraint(base_type,\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:59 _SatisfiesTypeConstraint\n        raise TypeError(\n\n    TypeError: Value passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64, int32\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d6af7e1cb810>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mroi_gray_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgray_frame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mcropped_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroi_gray_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0memotion_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memotion_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcropped_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mmaxindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memotion_prediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memotion_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmaxindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLINE_AA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1725\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1727\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1728\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1525 predict_step\n        return self(x, training=False)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:394 call\n        outputs = layer(inputs, **kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:1447 call\n        return getattr(self._module, self._method_name)(*args, **kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py:1006 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\layers\\convolutional.py:245 call\n        outputs = self._convolution_op(inputs, self.kernel)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1012 convolution_v2\n        return convolution_internal(\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1142 convolution_internal\n        return op(\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:2596 _conv2d_expanded_batch\n        return gen_nn_ops.conv2d(\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:968 conv2d\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:628 _apply_op_helper\n        _SatisfiesTypeConstraint(base_type,\n    C:\\Users\\a\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:59 _SatisfiesTypeConstraint\n        raise TypeError(\n\n    TypeError: Value passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64, int32\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    # Find haar cascade to draw bounding box around face\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    bounding_box = cv2.CascadeClassifier(\"C:/Users/a/Documents/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml\")\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    num_faces = bounding_box.detectMultiScale(gray_frame,scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in num_faces:\n",
    "        cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n",
    "        roi_gray_frame = gray_frame[y:y + h, x:x + w]\n",
    "        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray_frame, (48, 48)), -1), 0)\n",
    "        emotion_prediction = emotion_model.predict(cropped_img)\n",
    "        maxindex = int(np.argmax(emotion_prediction))\n",
    "        cv2.putText(frame, emotion_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Video', cv2.resize(frame,(1200,860),interpolation = cv2.INTER_CUBIC))\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34b91f44-7397-4c81-8888-313b49a6c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3539f9ee-42bd-447e-bb45-afd203e49b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
